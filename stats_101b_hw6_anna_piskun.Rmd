---
title: "Stats 101B Homework #6"
author: "Anna Piskun"
date: "6/2/2020"
output: 
    pdf_document:
      latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop")
```

### Question 1

Q1) A textile mill has a large number of looms. Each loom is supposed to provide the same output of cloth per minute. To investigate this assumption, five looms are chosen at random, and their output is noted at different times. The following data are obtained:

```{r}
data.1 <- read.csv("HW6 S2020 Q1 Data.csv")
model <- aov(Output~factor(Loom), data = data.1)
summary(model)
```

(a) Explain why this is a random effects experiment. Are the looms equal in output? Use (𝛼𝛼 = 0.05).

Given the above information, this is a random effects experiment since all of the looms (aka our treatment factor) used in the experiment are chosen at random to form a random sample of all looms in the manufacturing area. Looking at our anova analysis, the pvalue of 0.00296 is statistically significant. Since the pvalue is less than 0.05, we reject the null hypothesis that there is no difference in loom output. Thus, we find that the looms are NOT equal in output. 

(b) Estimate the variability between looms.

```{r}
a <- (anova(aov(Output~factor(Loom), data = data.1))[,3])
#the variability between looms
(a[1]-a[2])/5
```

(c) Estimate the experimental error variance.

```{r}
#experimental error variance is just the MSerror 
(anova(aov(Output~factor(Loom), data = data.1))[2,3])
```

(d) Find a 95 percent confidence interval for the ICC

```{r}
#using the anova output we can calculate the confidence interval by hand 

#Lower Bound 

f.low <- qf(0.025,4,20, lower.tail = FALSE)

lb <- (1/5)*((0.0854/0.0148)*(1/f.low) - 1)
lb/(lb+1)
#Upper Bound 

f.upper <- qf(0.975, 4, 20, lower.tail = FALSE)

ub <- (1/5)*((0.0854/0.0148)*(1/f.upper) - 1)
ub/(ub+1)


```

Therefore, a 95% CI is [0.114, 0.9064]. 

(e) Analyze the residuals from this experiment. Do you think that the analysis of variance assumptions are satisfied?

```{r}
plot(model, which = 1:2)

#Residuals vs. Loom
library(lattice)
df1 <- data.frame(x = as.factor(data.1$Loom), y = model$residuals) 
xyplot(y~x, data = df1,
        xlab = "Type of Loom",
       ylab = "Residuals", 
       main = "Residuals vs. Loom")

```

Looking at the residuals vs. fitted values plot we see evidence of a slight fanshape which may indicate non constant variance. Specifically looking at the residuals vs. loom plot, we that there are about equal points above and below 0 at each loom which indicates good model fit, however, the fluctuations of the residuals themseleves within each factor are not similar across all 5 levels indicating that the constant variance assumption is not satisfied. Likewise, analyzing the normal probability plot it is quite curvy and there is some deviation from a straight line indicating that the errors are not normally distributed and the normality assummption is not satisfied. 


(f) Use the REML method to analyze this data. Compare the 95 percent confidence interval on the error variance from REML with the exact chi-square confidence interval.

```{r}
library(lme4)
m2 <- lmer(Output ~ (1|Loom), data=data.1)
m2reduced <- lm(Output~factor(Loom), data = data.1)
summary(m2)
logLik(m2reduced)
logLik(m2)

chisquare.test <- 2*(19.97993-11.38814)
chisquare.test
pvalue <- 1- pchisq(17.18358,3)
pvalue
```

Using the log-liklihood ratio test to complete our chi-square distribution, we get a pvalue of 0.0006 which is less than 0.05 meaning that we reject the null hypothesis and conclude that the Looms are truly different from each other. 

Q2) An engineer is interested in the effects of cutting speed (A), tool geometry (B), and cutting angle (C) on the life (in hours) of a machine tool. Two levels of each factor are chosen, and three replicates of a 23 factorial design are run. The results are as follows:

```{r}
data.2 <- read.csv("HW6 S2020 Q2 Data.csv")
```

(a) Estimate the factor effects. Which effects appear to be large?

```{r}
summary(lm(Life.Hours~Cutting.Speed*Tool.Geometry*Cutting.Angle, data = data.2))
```

The effects that appear to be large are Tool.Geometry (B), Cutting Angle (C), and the interaction between Cutting Speed (A) and Cutting Angle (C). 

(b) Use the analysis of variance to confirm your conclusions for part (a).

```{r}
summary(aov(Life.Hours~Cutting.Speed*Tool.Geometry*Cutting.Angle, data = data.2))
```

Looking at our anova table above, we see that Tool.Geometry (B), Cutting.Angle (C), and the interaction between Cutting.Speed and Cutting.Angle (AC) are all statistically significant (less than 0.05), which confirms our conclusions for part a. 

(c) Write down a regression model for predicting tool life (in hours) based on the results of this experiment.

Using our above analysis we can write a regression model for predicting tool life only using the statistically significant factors. Thus we get the following model: 

Y = 40.833 + 5.6667(B) + 3.4167(C) - 4.4167(AC) 

```{r}
model.2 <- lm(Life.Hours~Tool.Geometry+Cutting.Angle+Cutting.Speed*Cutting.Angle, data = data.2)
summary(model.2)
```

(d) Analyze the residuals. Are there any obvious problems?

```{r}
plot(model.2, which = 1:2)

library(lattice)
df2 <- data.frame(x = as.factor(data.2$Tool.Geometry), y = model.2$residuals) 
xyplot(y~x, data = df2,
        xlab = "Tool Geometry",
       ylab = "Residuals", 
       main = "Residuals vs. Tool Geometry")

df3 <- data.frame(x = as.factor(data.2$Cutting.Angle), y = model.2$residuals) 
xyplot(y~x, data = df3,
        xlab = "Cutting Angle",
       ylab = "Residuals", 
       main = "Residuals vs. Cutting Angle")

```

Looking at the above residual plots, there are no clear patterns or fanshapes and there are about equal points above and below 0 within the factor specific plots which indicates good model fit. Likewise, the fluctuations of the residuals themseleves within each factor are similar across all levels indicating that the constant variance assumption is met. However, the normal probability plot is slightly curvy which may indicate that the errors are not normally distributed. Aside from that, there are no obvious problems with the model. 


(e) On the basis of an analysis of main effect and interaction plots, what coded factor levels of A, B, and C would you recommend using?

```{r}

interaction.plot(x.factor = data.2$Cutting.Speed, trace.factor = data.2$Cutting.Angle,
                 response = data.2$Life.Hours, fun = base::mean, trace.label = "Cutting Angle", 
                 col = c("red", "blue"), 
                 xlab = "Cutting Speed", ylab = "Life Span of a Machine Tool (hours)", 
                 main = "Interaction b/w Cutting Speed and Cutting Angle")

library(gplots)
plotmeans(Life.Hours~Tool.Geometry, data = data.2,
          xlab="Factor B",ylab="Mean Life Hours", 
          main = "Main Effect Plot for B")

plotmeans(Life.Hours~Cutting.Angle, data = data.2,
          xlab="Factor C",ylab="Mean Life Hours", 
          main = "Main Effect Plot for C")
```

Using the above main effect plots and interaction plot, we see that mean tool life is highest when (A,B,C) = (-, +, +). Thus I would recommend the coded factor levels of -1 for A, 1 for B, and 1 for C. 


Q3) I am always interested in improving my golf scores. Since a typical golfer uses the putter for about 35–45 percent of his or her strokes, it seems reasonable that improving one’s putting is a logical and perhaps simple way to improve a golf score (“The man who can putt is a match for any man.”— Willie Parks, 1864–1925, two-time winner of the British Open). An experiment was conducted to study the effects of four factors on putting accuracy. The design factors are length of putt, type of putter, breaking putt versus straight putt, and level versus downhill putt. The response variable is distance from the ball to the center of the cup after the ball comes to rest. One golfer performs the experiment, a 24 factorial design with seven replicates was used, and all putts are made in random order. The results are shown in Table P6.4.

```{r}
data.3 <- read.csv("HW6 S2020 Q3  Data.csv")
```

(a) Analyze the data from this experiment. Which factors significantly affect putting performance?

```{r}
summary(aov(Distance.from.Cup~factor(Length.of.Putt)*factor(Type.of.Putter)*factor(Break.of.Putt)*factor(Slope.of.Putt), data = data.3))
```

Using our analysis of variance, we find that only two factors, Length of Putt (A) and Type of Putter (B), significantly affect putting performance. Thus, we can create a model using only statistically significant factors which can be seen below: 

```{r}
model.3 <- lm(Distance.from.Cup~Length.of.Putt+Type.of.Putter, data = data.3)
summary(model.3)
```


(b) Analyze the residuals from this experiment. Are there any indications of model inadequacy?

```{r}
plot(model.3, which = 1:2)

library(lattice)
df5 <- data.frame(x = as.factor(data.3$Length.of.Putt), y = model.3$residuals) 
xyplot(y~x, data = df5,
        xlab = "Length of Putt",
       ylab = "Residuals", 
       main = "Residuals vs. Length of Putt")

df6 <- data.frame(x = as.factor(data.3$Type.of.Putter), y = model.3$residuals) 
xyplot(y~x, data = df6,
        xlab = "Type of Putter",
       ylab = "Residuals", 
       main = "Residuals vs. Type of Putter")
```

Analyzing the above residual plots we see a fanshape in the residuals vs. fitted plot which indicates non constant variance. This is further confirmed with the individual residual plots for the two significant factors A and B which show unequal fluctuations of the residuals within each factor. Additionally, there is significant curvature in the normal probability plot which indicates that the normality assumption is not satisfied. Therefore, since both the normality and constant variance conditions are not met this model is not valid. 










